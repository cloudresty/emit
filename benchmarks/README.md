# Emit Benchmarks

Comprehensive performance benchmarks comparing **Emit**, **Zap**, and **Logrus** logging libraries.

## ğŸ—ï¸ Architecture

The benchmark suite is organized into modular, maintainable components:

### Core Files

- **`benchmark.go`** - Main orchestration and result collection
- **`emit-benchmark-set.go`** - All Emit logging benchmarks
- **`zap-benchmark-set.go`** - All Zap logging benchmarks
- **`logrus-benchmark-set.go`** - All Logrus logging benchmarks
- **`markdown-export.go`** - GitHub-friendly Markdown result formatting

### Output

- **`benchmark-results.md`** - Human-readable results (viewable directly on GitHub)

## ğŸš€ Running Benchmarks

```bash
# Build the benchmark application
go build .

# Run all benchmarks (takes 3-5 minutes)
./benchmarks

# View results
cat benchmark-results.md
```

## ğŸ“Š What Gets Benchmarked

### Fair Comparison Methodology

All benchmarks use **identical data** and **identical scenarios** across libraries:

- **Same log messages**
- **Same field names and values**
- **Same data types and complexity**
- **Same output destinations** (all sent to `/dev/null`)

### Benchmark Categories

#### 1. **Simple Message Logging**

- Basic string messages
- Minimal overhead scenarios

#### 2. **Structured Field Logging**

- Multiple typed fields
- Complex nested operations
- Real-world microservice scenarios

#### 3. **Zero-Allocation/High-Performance**

- Memory-optimized APIs
- Hot-path logging scenarios

#### 4. **ğŸ”’ Security Benchmarks** â­

This is where Emit truly shines:

- **Emit with Built-in Security** - Automatic PII/sensitive masking (default)
- **Emit without Security** - Using non-triggering field names (unsafe but fast)
- **Zap without Security** - Default behavior (fast but exposes data)
- **Zap with Manual Security** - Developer-implemented masking (slow + error-prone)
- **Logrus without Security** - Default behavior (slow + exposes data)
- **Logrus with Manual Security** - Developer-implemented masking (slowest)

## ğŸ›¡ï¸ Security Focus

### Automatic vs Manual Masking

**Emit automatically masks these field patterns:**

```go
// PII fields (â†’ "***PII***")
"email", "phone", "ssn", "address", "ip_address"

// Sensitive fields (â†’ "***MASKED***")
"password", "api_key", "token", "secret", "private_key"
```

**Other libraries require manual implementation:**

```go
// Zap/Logrus - developer must implement masking
maskSensitive := func(s string) string {
    return s[:2] + "***" + s[len(s)-2:]
}
```

### Real-World Security Impact

The security benchmarks demonstrate:

1. **Performance Cost** - Manual masking adds 20-40% overhead
2. **Development Risk** - Easy to forget masking sensitive fields
3. **Compliance Benefits** - Emit provides automatic GDPR/CCPA compliance
4. **Zero Configuration** - Security works out-of-the-box

## ğŸ“ˆ Expected Results

Based on Apple M1 Max performance:

```plain
Performance Ranking (ns/op - lower is better):
1. Emit Simple       ~56 ns/op     â† Fastest
2. Emit ZeroAlloc    ~174 ns/op    â† With security!
3. Zap Simple        ~88 ns/op     â† No security
4. Emit Structured   ~345 ns/op    â† With security!
5. Zap Structured    ~400+ ns/op   â† No security
6. Logrus Simple     ~1,393 ns/op  â† No security
7. Logrus Structured ~2,000+ ns/op â† No security
```

**Key Insight:** Emit with automatic security is faster than Zap/Logrus without any security!

## ğŸ¯ Understanding the Results

### Metrics Explained

- **ns/op** - Nanoseconds per operation (lower = faster)
- **B/op** - Bytes allocated per operation (lower = more memory efficient)
- **allocs/op** - Memory allocations per operation (lower = better)
- **ops/sec** - Operations per second (higher = better throughput)

### Performance Categories

- **< 100 ns/op** - Excellent (suitable for hot paths)
- **100-500 ns/op** - Very Good (suitable for normal operations)
- **500-1000 ns/op** - Good (acceptable for most use cases)
- **> 1000 ns/op** - Poor (consider optimization)

### Security Trade-offs

View the security benchmarks to understand:

- Performance cost of manual security implementations
- Development complexity of secure logging
- Benefits of automatic protection

## ğŸ’¡ Interpretation Guide

When viewing `benchmark-results.md`:

1. **Check Simple Message benchmarks** - Base performance comparison
2. **Review Security benchmarks** - Real-world security vs performance
3. **Compare Structured logging** - Complex operation performance
4. **Note memory allocations** - Important for high-throughput systems

## ğŸ”„ Benchmark Validity

All benchmarks ensure fair comparison by:

- Using identical hardware and environment
- Running multiple iterations for statistical validity
- Measuring only the logging operation (excluding setup)
- Using production-equivalent configurations
- Eliminating I/O bottlenecks (output to `/dev/null`)

---

**Result:** Emit delivers superior performance while providing automatic security that other libraries cannot match.
